# Prometheus Alert Rules –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ erni-ki
# –ü—Ä–∞–≤–∏–ª–∞ –∞–ª–µ—Ä—Ç–∏–Ω–≥–∞ –¥–ª—è AI —Å–µ—Ä–≤–∏—Å–æ–≤ –∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

groups:
  # –û–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
  - name: infrastructure.rules
    rules:
      # –°–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          category: infrastructure
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} on {{ $labels.instance }} has been down for more than 1 minute."

      # –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          category: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% for more than 5 minutes on {{ $labels.instance }}."

      # –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          category: infrastructure
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% for more than 5 minutes on {{ $labels.instance }}."

      # –ú–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
      - alert: LowDiskSpace
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: critical
          category: infrastructure
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk usage is above 90% on {{ $labels.instance }} ({{ $labels.mountpoint }})."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è Auth —Å–µ—Ä–≤–∏—Å–∞
  - name: auth-service.rules
    rules:
      # Auth —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: AuthServiceDown
        expr: up{job="auth-service"} == 0
        for: 30s
        labels:
          severity: critical
          service: auth
          category: security
        annotations:
          summary: "Auth service is down"
          description: "Authentication service has been down for more than 30 seconds. This affects all protected endpoints."

      # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
      - alert: HighAuthErrorRate
        expr: rate(auth_requests_total{status=~"4.."}[5m]) / rate(auth_requests_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
          service: auth
          category: security
        annotations:
          summary: "High authentication error rate"
          description: "Authentication error rate is above 10% for more than 2 minutes."

      # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–º–Ω–æ–≥–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫)
      - alert: SuspiciousAuthActivity
        expr: rate(auth_requests_total{status="401"}[1m]) > 10
        for: 1m
        labels:
          severity: critical
          service: auth
          category: security
        annotations:
          summary: "Suspicious authentication activity detected"
          description: "High rate of failed authentication attempts detected. Possible brute force attack."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è Ollama (AI —Å–µ—Ä–≤–∏—Å)
  - name: ollama.rules
    rules:
      # Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: OllamaDown
        expr: up{job="ollama"} == 0
        for: 1m
        labels:
          severity: critical
          service: ollama
          category: ai
        annotations:
          summary: "Ollama service is down"
          description: "Ollama LLM service has been down for more than 1 minute."

      # –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
      - alert: HighGPUUsage
        expr: nvidia_gpu_utilization_gpu > 95
        for: 10m
        labels:
          severity: warning
          service: ollama
          category: ai
        annotations:
          summary: "High GPU usage"
          description: "GPU utilization is above 95% for more than 10 minutes."

      # –í—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ GPU
      - alert: GPUHighTemperature
        expr: nvidia_gpu_temperature_celsius > 85
        for: 3m
        labels:
          severity: critical
          service: ollama
          category: hardware
        annotations:
          summary: "üî• GPU temperature is critical"
          description: "GPU temperature is {{ $value }}¬∞C, which is above the safe threshold."

      # –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU
      - alert: GPUHighMemoryUsage
        expr: (nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: ollama
          category: hardware
        annotations:
          summary: "üíæ GPU memory usage is high"
          description: "GPU memory usage is {{ $value }}%."

      # –í—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ GPU
      - alert: HighGPUTemperature
        expr: nvidia_gpu_temperature > 85
        for: 5m
        labels:
          severity: critical
          service: ollama
          category: ai
        annotations:
          summary: "High GPU temperature"
          description: "GPU temperature is above 85¬∞C for more than 5 minutes."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è Open WebUI
  - name: openwebui.rules
    rules:
      # Open WebUI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: OpenWebUIDown
        expr: up{job="openwebui"} == 0
        for: 1m
        labels:
          severity: critical
          service: openwebui
          category: ai
        annotations:
          summary: "Open WebUI is down"
          description: "Open WebUI service has been down for more than 1 minute."

      # –í—ã—Å–æ–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤
      - alert: HighResponseLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="openwebui"}[5m])) > 5
        for: 5m
        labels:
          severity: warning
          service: openwebui
          category: performance
        annotations:
          summary: "High response latency in Open WebUI"
          description: "95th percentile latency is above 5 seconds for more than 5 minutes."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è PostgreSQL
  - name: postgres.rules
    rules:
      # PostgreSQL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: PostgreSQLDown
        expr: up{job="postgres"} == 0
        for: 30s
        labels:
          severity: critical
          service: postgres
          category: database
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL database has been down for more than 30 seconds."

      # –ú–Ω–æ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
      - alert: PostgreSQLTooManyConnections
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
          service: postgres
          category: database
        annotations:
          summary: "Too many PostgreSQL connections"
          description: "PostgreSQL has more than 80 active connections for more than 5 minutes."

      # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
      - alert: PostgreSQLSlowQueries
        expr: pg_stat_activity_max_tx_duration > 300
        for: 2m
        labels:
          severity: warning
          service: postgres
          category: database
        annotations:
          summary: "PostgreSQL slow queries detected"
          description: "PostgreSQL has queries running for more than 5 minutes."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è Redis
  - name: redis.rules
    rules:
      # Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 30s
        labels:
          severity: critical
          service: redis
          category: cache
        annotations:
          summary: "Redis is down"
          description: "Redis cache service has been down for more than 30 seconds."

      # –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ Redis
      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          service: redis
          category: cache
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is above 90% for more than 5 minutes."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è Nginx
  - name: nginx.rules
    rules:
      # Nginx –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: NginxDown
        expr: up{job="nginx"} == 0
        for: 30s
        labels:
          severity: critical
          service: nginx
          category: proxy
        annotations:
          summary: "Nginx is down"
          description: "Nginx reverse proxy has been down for more than 30 seconds."

      # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ 5xx
      - alert: NginxHighErrorRate
        expr: rate(nginx_http_requests_total{status=~"5.."}[5m]) / rate(nginx_http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          service: nginx
          category: proxy
        annotations:
          summary: "High Nginx error rate"
          description: "Nginx 5xx error rate is above 5% for more than 5 minutes."

  # –ü—Ä–∞–≤–∏–ª–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
  - name: security.rules
    rules:
      # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ç—Ä–∞—Ñ–∏–∫
      - alert: SuspiciousTraffic
        expr: rate(nginx_http_requests_total[1m]) > 1000
        for: 1m
        labels:
          severity: warning
          category: security
        annotations:
          summary: "Suspicious traffic detected"
          description: "High request rate detected. Possible DDoS attack."

      # –ú–Ω–æ–≥–æ 403 –æ—à–∏–±–æ–∫ (–≤–æ–∑–º–æ–∂–Ω–∞—è –∞—Ç–∞–∫–∞)
      - alert: HighForbiddenRate
        expr: rate(nginx_http_requests_total{status="403"}[5m]) > 10
        for: 2m
        labels:
          severity: warning
          category: security
        annotations:
          summary: "High rate of forbidden requests"
          description: "High rate of 403 errors detected. Possible scanning or attack attempt."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Cloudflare
  - name: cloudflare.rules
    rules:
      # Cloudflared —Ç—É–Ω–Ω–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: CloudflaredTunnelDown
        expr: up{job="cloudflared"} == 0
        for: 2m
        labels:
          severity: critical
          service: cloudflared
          category: network
        annotations:
          summary: "Cloudflare tunnel is down"
          description: "Cloudflare tunnel has been down for more than 2 minutes. External access may be unavailable."

      # –í—ã—Å–æ–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —á–µ—Ä–µ–∑ Cloudflare —Ç—É–Ω–Ω–µ–ª—å
      - alert: CloudflareHighLatency
        expr: probe_duration_seconds{job="blackbox-cloudflare"} > 5
        for: 5m
        labels:
          severity: warning
          service: cloudflared
          category: network
        annotations:
          summary: "High latency through Cloudflare tunnel"
          description: "Cloudflare tunnel latency is above 5 seconds for more than 5 minutes."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ)
  - name: gpu-monitoring.rules
    rules:
      # GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: GPUUnavailable
        expr: up{job="nvidia-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          service: nvidia
          category: ai
        annotations:
          summary: "GPU monitoring unavailable"
          description: "NVIDIA GPU exporter has been down for more than 1 minute."

      # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
      - alert: CriticalGPUUsage
        expr: nvidia_gpu_utilization > 98
        for: 15m
        labels:
          severity: critical
          service: ollama
          category: ai
        annotations:
          summary: "Critical GPU usage"
          description: "GPU utilization is above 98% for more than 15 minutes. Performance may be severely degraded."

      # –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏
      - alert: HighGPUMemoryUsage
        expr: (nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes) * 100 > 90
        for: 10m
        labels:
          severity: warning
          service: ollama
          category: ai
        annotations:
          summary: "High GPU memory usage"
          description: "GPU memory usage is above 90% for more than 10 minutes."

      # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ GPU
      - alert: CriticalGPUTemperature
        expr: nvidia_gpu_temperature > 90
        for: 2m
        labels:
          severity: critical
          service: ollama
          category: ai
        annotations:
          summary: "Critical GPU temperature"
          description: "GPU temperature is above 90¬∞C for more than 2 minutes. Risk of hardware damage."

      # –ù–∏–∑–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å GPU
      - alert: LowGPUPerformance
        expr: nvidia_gpu_power_draw < 50
        for: 30m
        labels:
          severity: warning
          service: ollama
          category: ai
        annotations:
          summary: "Low GPU performance"
          description: "GPU power draw is below 50W for more than 30 minutes. GPU may be throttling."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG
  - name: rag-performance.rules
    rules:
      # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ RAG –∑–∞–ø—Ä–æ—Å—ã
      - alert: SlowRAGQueries
        expr: histogram_quantile(0.95, rate(openwebui_rag_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          service: openwebui
          category: performance
        annotations:
          summary: "Slow RAG queries detected"
          description: "95th percentile RAG query time is above 2 seconds for more than 5 minutes."

      # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–µ–¥–ª–µ–Ω–Ω—ã–µ RAG –∑–∞–ø—Ä–æ—Å—ã
      - alert: CriticalSlowRAGQueries
        expr: histogram_quantile(0.95, rate(openwebui_rag_duration_seconds_bucket[5m])) > 10
        for: 2m
        labels:
          severity: critical
          service: openwebui
          category: performance
        annotations:
          summary: "Critical slow RAG queries"
          description: "95th percentile RAG query time is above 10 seconds for more than 2 minutes."

      # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–µ—É–¥–∞—á–Ω—ã—Ö RAG –∑–∞–ø—Ä–æ—Å–æ–≤
      - alert: HighRAGFailureRate
        expr: rate(openwebui_rag_requests_total{status="error"}[5m]) / rate(openwebui_rag_requests_total[5m]) > 0.1
        for: 3m
        labels:
          severity: warning
          service: openwebui
          category: performance
        annotations:
          summary: "High RAG failure rate"
          description: "RAG failure rate is above 10% for more than 3 minutes."

  # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ SearXNG
  - name: searxng-performance.rules
    rules:
      # SearXNG –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      - alert: SearXNGDown
        expr: up{job="searxng"} == 0
        for: 1m
        labels:
          severity: critical
          service: searxng
          category: search
        annotations:
          summary: "SearXNG is down"
          description: "SearXNG search service has been down for more than 1 minute."

      # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã SearXNG
      - alert: SlowSearXNGQueries
        expr: histogram_quantile(0.95, rate(searxng_request_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
          service: searxng
          category: performance
        annotations:
          summary: "Slow SearXNG queries"
          description: "95th percentile SearXNG query time is above 5 seconds for more than 5 minutes."

      # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
      - alert: HighSearXNGFailureRate
        expr: rate(searxng_requests_total{status=~"4..|5.."}[5m]) / rate(searxng_requests_total[5m]) > 0.2
        for: 3m
        labels:
          severity: warning
          service: searxng
          category: search
        annotations:
          summary: "High SearXNG failure rate"
          description: "SearXNG failure rate is above 20% for more than 3 minutes."
